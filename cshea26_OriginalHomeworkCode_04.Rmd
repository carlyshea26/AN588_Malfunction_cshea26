---
title: "cshea26_OriginalHomeworkCode_04"
author: "Carly S McDermott"
date: "2025-03-14"
output: 
  html_document:
    theme: flatly
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

INFO: 
- Z and T tests are used to evaluate whether a given sample statistic (e.g., a mean or proportion) deviates significantly from what is expected under a null model or whether two samples statistics deviate significantly from one another.

- We REJECT a H0 if the p value obtained for a given Z or T test statistic is < Œ±
CIs for our sample statistic are calculated as mean ¬± T(1‚àíŒ±/2) or Z(1‚àíŒ±/2) x SEM, and we can REJECT a H0 if the (1-Œ±) CI around does not include the expected value of the statistic
When the sample size > 30, or when we are dealing with proportions, we use Z quantiles for calculating CIs and p values, but for sample size < 30, we use T quantiles



## 1) Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:
- Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample‚Äôs proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default ‚Äútwo.sided‚Äù) and conf.level (default 0.95), to be used in the same way as in the function t.test().
- When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=‚Äúless‚Äù or alternative=‚Äúgreater‚Äù, the same as in the use of x and y in the function t.test().
The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.
- The function should contain a check for the rules of thumb we have talked about (\(n * p > 5\) and \(n * (1-p) > 5\)) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
- The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to ‚Äúconf.level‚Äù around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). - For all test alternatives (‚Äútwo.sided‚Äù, ‚Äúgreater‚Äù, ‚Äúless‚Äù), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}
Z.prop.test <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95) {
  if (is.null(p2) || is.null(n2)) {
    z <- (p1 - p0)/sqrt(p0 * (1 - p0)/n1) #mean of sample observations minus expected mean, divided by sample standard of deviations divided by square root of number of sample observations
    if (alternative == "greater") {
      pval <- pnorm(z, lower.tail = FALSE) #checking if alternative is greater or less than (indicates if we need to use upper or lower tail)
    } else if (alternative == "less") {
      pval <- pnorm(z, lower.tail = TRUE)
    } else if (alternative == "two.sided") { #otherwise checking if z is greater than zero, if so we do a lower tail test, if not we do an upper tail test
      if (z > 0) {
        pval <- 2 * pnorm(z, lower.tail = FALSE)
      } else {
        pval <- 2 * pnorm(z, lower.tail = TRUE)
      }
    }
    
    #creating warning message to ensure the validity of assuming the normal distribution
    if ((n1 * p0 > 5) || (n1 * (1-p0) > 5)) {
      warning("invalid assumption of normal distribution") 
    }
    
    lower <- p1 - qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
    upper <- p1 + qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
    ci <- c(lower, upper) #creating confidence interval based on upper and lower bounds (.975 and .025)
    
    result <- list(test.type = "One-Sample Proportion Z-test", 
                                alternative = alternative,
                                z.test.stat = as.numeric(z), 
                                p.value = as.numeric(pval), 
                                confidence.interval = ci)
    return(result)
  } else {
    pstar <- ((p1*n1) + (p2*n2))/(n1 + n2) 
    
    z <- (p2 - p1)/sqrt((pstar * (1 - pstar)) * (1/n1 + 1/n2))
    
    if (alternative == "greater") {
        pval <- pnorm(z, lower.tail = FALSE)
      }
      if (alternative == "less") {
        pval <- pnorm(z, lower.tail = TRUE)
      }
      if (alternative == "two.sided") {
        pval <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)
          }
    
    if ((n1 * p0 < 5) | (n1 * (1 - p0) < 5 ) | (n2 * p0 < 5) | (n2 * (1 - p0) < 5)) {
      warning("invalid assumption of normal distribution")
  }
  a = 1 - (conf.level)
  crit <- qnorm(1 - a/2)
  
  upper <- (p1 - p2) + (crit) * (sqrt((p1*(1-p1)/n1) + (p2 * (1-p2)/n2)))
  lower <- (p1 - p2) - (crit) * (sqrt((p1*(1-p1)/n1) + (p2 * (1-p2)/n2)))
  ci <- c(lower, upper)
  
    result2 <- list(test.type = "Two-Sample Proportion Z-test", 
                                alternative = alternative,
                                z.test.statistic = as.numeric(z), 
                                p.value = as.numeric(pval), 
                                confidence.interval = ci, 
                                critical.value = as.numeric(crit))
    return(result2)
  }
}

#need to create test now to validate results, i will try to do for final submission but am unsure what to use
```

## Question 2) The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. 
- For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species‚Äô brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):

## Part 1: 
Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text())
reattempt:
```{r}
library(curl)
library(ggplot2)
library(ggpubr)
library(gridExtra)

data <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv") #load data
data <- read.csv(data, header = TRUE, sep = ",", stringsAsFactors = FALSE)
data <- na.omit(data) # clean data to get longevity and brain size (NA categories)
Brain_Size_Species_Mean <- data$Brain_Size_Species_Mean

#creating model1: longevity ~ brain size
model1 <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = data) #coef returns standardized model regression coefficients
intercept1 <- coef(model1)["(Intercept)"]
slope1 <- coef(model1)["Brain_Size_Species_Mean"]

# creating model 2: log(longevity) ~ log(brain size), doing the same as above but with the logs
model2 <- lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data = data)
intercept2 <- coef(model2)["(Intercept)"]
slope2 <- coef(model2)["log(Brain_Size_Species_Mean)"]

#plotting model1 in ggplot as p1
p1 <- ggplot(data, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = intercept1, slope = slope1, color = "blue") + geom_text(aes(x = max(Brain_Size_Species_Mean), y = max(MaxLongevity_m), 
#this next part gives me my equation for the line                                                              
                label = paste("y = ", round(coef(model1)[1], 2), " + ", round(coef(model1)[2], 2), " * x")), 
            hjust = 1, vjust = 1, size = 5) +
  labs(title = "Longevity vs Brain Size", x = "Brain Size (grams)", y = "Max Longevity (months)") +  theme_minimal()
p1 

#p2 represents linear regression plot for logs
p2 <- ggplot(data, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m))) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = intercept2, slope = slope2, color = "red") +
  geom_text(aes(x = max(log(Brain_Size_Species_Mean)), y = max(log(MaxLongevity_m)), 
                label = paste("y = ", round(coef(model2)[1], 2), " + ", round(coef(model2)[2], 2), " * x")), 
            hjust = 1, vjust = 1) +
  labs(title = "Log of Brain Size vs. Log of Longevity", x = "Log of Longevity", y = "Log of Brain Size") +
  theme_minimal()
p2

grid.arrange(p1, p2, ncol = 2)
```
- tried to use geom_smooth() but didn't like how the line it created wasn't making contact with the x axis. is there a way to fix this while still using geom smooth? instead here i just plotted a line equal to the intercept and slope i established above with my two models

## Part 2: 

Identify and interpret the point estimate of the slope (Œ≤1), as well as the outcome of the test associated with the hypotheses H0: Œ≤1 = 0; HA: Œ≤1 ‚â† 0. Also, find a 90 percent CI for the slope (Œ≤1) parameter.

An equation I used to calculate beta 1: 
- beta1 <- cor(w, h) * (sd(h)/sd(w))
where 
- w <- d$weight (longevity)
- h <- d$height (brain size)
```{r}
w <- data$MaxLongevity_m
h <- data$Brain_Size_Species_Mean
beta1 <- cor(w, h) * (sd(h)/sd(w))
beta1

#to determine beta1 for the log plots
w <- log(data$MaxLongevity_m)
h <- log(data$Brain_Size_Species_Mean)
beta1 <- cor(w, h) * (sd(h)/sd(w))
beta1
```
- I'm not entirely sure what a nonzero value of  ùõΩ1 signifies? Rejecting some sort of null hypothesis? Would love some input
- My best guess: the estimated ùõΩ1 in both cases yields a non-zero value, meaning that we can reject the null hypothesis H0 which argues that ùõΩ1 = 0, and therefore accept the HA (alternative hypothesis) that ùõΩ1 does not equal 0.

## Part 3: 

Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

For model 1: 
```{r}
v <- seq(from = min(data$Brain_Size_Species_Mean), to = max(data$Brain_Size_Species_Mean), length.out = 100)
m <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = data)
ci <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.90)
pi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.90)

#cannot figure out how to do it with ggplot so doing it with general plot function
plot(data$Brain_Size_Species_Mean, data$MaxLongevity_m)
lines(v, ci[, 1], col = "black")
lines(v, pi[, 2], col = "red")
lines(v, pi[, 3], col = "red")
```
For model 2: 
```{r}
data$log_Brain_Size <- log(data$Brain_Size_Species_Mean)
data$log_Longevity <- log(data$MaxLongevity_m)
m2 <- lm(log_Longevity ~ log_Brain_Size, data = data)
v_log <- seq(from = min(data$log_Brain_Size), to = max(data$log_Brain_Size), length.out = 100)

ci <- predict(m2, newdata = data.frame(log_Brain_Size = v_log), interval = "confidence", level = 0.90)
pi <- predict(m2, newdata = data.frame(log_Brain_Size = v_log), interval = "prediction", level = 0.90)

plot(data$log_Brain_Size, data$log_Longevity, 
     xlab = "Log Brain Size", 
     ylab = "Log Max Longevity", 
     main = "Log Regression of Brain Size vs. Longevity")
lines(v_log, ci[, 1], col = "black")  
lines(v_log, pi[, 2], col = "red")    
lines(v_log, pi[, 3], col = "red")  


#is this how i could do this with ggplot? offered an alternative that looks more similar to how we did it in module 12
ci_df <- as.data.frame(ci)
pi_df <- as.data.frame(pi)

# Rename columns to prevent duplication
colnames(ci_df) <- c("fit", "ci_lwr", "ci_upr")
colnames(pi_df) <- c("fit_pred", "pi_lwr", "pi_upr")

# Combine into a single data frame
pred_df <- data.frame(log_Brain_Size = v_log, ci_df, pi_df)

# Plot using ggplot2
ggplot(data, aes(x = log_Brain_Size, y = log_Longevity)) +
  geom_point() +
  geom_line(data = pred_df, aes(x = log_Brain_Size, y = fit), color = "black") +  
  geom_line(data = pred_df, aes(x = log_Brain_Size, y = pi_lwr), color = "red") +   
  geom_line(data = pred_df, aes(x = log_Brain_Size, y = pi_upr), color = "red") + 
  labs(x = "Log Brain Size", y = "Log Max Longevity", 
       title = "Log Regression of Brain Size vs. Longevity") +
  theme_minimal()
```
I offered two different methods for the second model (the log one) for creating my confidence interval (one with plot and the other with ggplot). i'm open to any suggestions if anyone has any ideas on how to make these plots look better/more similar to the ones we see in the modules. 
- I also can't tell if the lines are straight

## Part 4: 

Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
```{r}
#for longevity ~ brain size
p1 <- predict(model1, newdata = data.frame(brain = 800), interval = "prediction", level = 0.90)
p1

#for the log
p2 <- predict(model2, newdata = data.frame(brain_log = 800), interval = "prediction", level = 0.90)
p2

new_value <- log(800)  # Log-transform the brain weight

# Compute prediction interval
pred_800 <- predict(m2, newdata = data.frame(log_Brain_Size = new_value), interval = "prediction", level = 0.90)

# Transform back to the original scale
exp(pred_800)
```
I think what I wrote above is correct, but why is it giving me all of these values as outputs
**Looking at your two models, which do you think is better? Why?**
- when asking the model to make predictions for large values that exceed the range for the majority of points in the longevity vs. brain size normal regression, i am not entirely sure that i trust its capacity to predict these values. the log transformed data appears much more evenly distributed and for that reason i trust the log plot/prediction to better capture my data.

1. I keep getting this warning message when I try to run my graphs and I have no idea how to get around it:
"Warning: [38;5;242mAll aesthetics have length 1, but the data has 26 rows. [36m‚Ñπ[38;5;242m Please consider using `annotate()` or provide this layer with data containing a single row."
2. I had the hardest time working on this homework assignment. Honestly creating confidence intervals was a nightmare and probably took like 4 hours and still I have no idea if they are correct.
3. I provided two different ways of making CIs for model 2 and would appreciate any feedback any peer commenter has regarding them. 
4. I also had a very difficult time trying to create the function for part one. Functions are definitely not my thing but I recognize their important. Any feedback on Part 1 would also be amazing. 
5. Something worth noting is that when I ran my rsquared values they were both very low, is the model that I created therefore not statistically signficant? Unsure
6. I also regocnize that I need to go back in and add more comments, which I will do before the final submission!